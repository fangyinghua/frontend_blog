
# http

###  http发展历程
* 早在 HTTP 建立之初，主要就是为了将超文本标记语言(HTML)文档从Web服务器传送到客户端的浏览器，用户端通过浏览器访问url地址来获取网页的显示内容。
* 到了 WEB2.0 以来，我们的页面变得复杂，不仅仅单纯的是一些简单的文字和图片，同时我们的 HTML 页面有了 CSS，Javascript，来丰富我们的页面展示，当 ajax 的出现，我们又多了一种向服务器端获取数据的方法，这些其实都是基于 HTTP 协议的。

1. http0.9
    使用“GET”方式从服务器获取HTML文档（纯文本格式）,并且在响应请求后立即关闭连接。
2. HTTP1.0 -- 1996年正式发布
    * 增加 HEAD、POST请求方式；(GET/POST/HEAD)
    * 增加响应状态码，标记可能错误的原因
    * 引入协议版本号概念；
    * 引入HTTP header头概念
    * 传输数据不限于文本
3. HTTP1.1 -- 1999年，HTTP1.1发布了RFC文档
    * 增加了 PUT、DELETE请求方法；
    * 增加了缓存管理和控制；
    * 明确了连接管理（默认长连接）;
    * 允许响应数据分块(chunked); --传输大文件
    * 强制要求添加Host头（虚拟主机）--没有Host头,400 Bad Request.

4. http2 -- HTTP/2标准于2015年5月 以RFC 7540正式发表
    * 前身 SPDY,2015年9月，google移除对SPDY的支持，抱 HTTP/2，在Chrome 51中生效；
    * 简称 h2(基于TLS/1.2或以上版本的加密连接) / h2c（非加密连接);
    * 多路复用：将一个TCP连接分为若干个流（Stream），每个流中可以传输若干消息（Message），每个消息由若干最小的二进制帧（Frame）组成。
        * 流：是连接中的一个虚拟信道，可以承载双向的消息；
        * 消息：是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧组成
        * 帧：客户端与服务器通过`交换帧来通信`，帧是基于这个新协议通信的最小单位。
    * 二进制帧 (http1.x基于文本，文本具有多样性)
    * 头部压缩(HPACK算法)--（Dynamic Table / Huffman Coding）;
    * 设置请求的优先级 
    * 服务端推送 -- 允许服务器直接提供浏览器渲染页面所需资源，而无须浏览器在收到、解析页面后再提起一轮请求，节约了加载时间。
    * 增强了安全性，“事实上”要求加密通信。
5. http3 -- 
    * 选择UDP作为底层传输层协议；
    * 流复用和流控：QUIC引入了连接上的多路流复用的概念。
    * 灵活的拥塞控制机制：更有效地利用可用的网络带宽，从而获得更好的吞吐量
    * 更好的错误处理能力：QUIC使用增强的丢失恢复机制和转发纠错功能，以更好地处理错误数据包。
    * 更快的握手：QUIC使用相同的TLS模块进行安全连接。QUIC的握手机制经过优化.

### http的状态码
* RFC规定状态码：三位数字组成，取值范围000-999;
* RFC把状态码分成5类：用数字的第一位表示分类，这样状态码范围变成100-599；


### 请求头、响应头

### http请求方法
### http缓存策略
### cookie/session/token

### 运输层协议（TCP、UDP）：
* 进程之间通信 -- 向上面的应用层提供通信服务；
* 为`应用进程之间`提供`端到端`的逻辑通信；
* 向高层用户屏蔽了下面网络核心细节(网络拓扑、所采用的路由选择协议等)；
* 复用（multiplexing）：发送方 不同的应用进程都可以使用同一个运输协议传送数据；
* 分用(demultiplexing)：接收方 的运输层在`剥去报文的首部`后能够把这些数据正确交付目的应用进程；

### TCP (传输控制协议 Transmission Control Protocol)
* 特点：
    * 提供面向连接服务(在传送数据前必须建立连接)
    * TCP不提交广播或者多播服务；
    * TCP提供可靠交付的服务。（无差错、不丢失、不重复、并且安全按序到达）。
    * TCP提过全双工通信。
        * 允许通信双方的应用进程在任何时候都能发送数据。
        * TCP连接的两端都设有`发送缓存`和`接收缓存`，用来临时存放双向通信的数据；
    * 每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）。
        TCP端点：套接字或者插口。（端口号拼接到IP地址--构成套接字）
    * 面向字节流（流：流入到进程或者从进程流出的`字节序列`）；
        * 把数据看成一连串的无结构字节流;
        * TCP不关心应用进程一次把多长的报文发送给TCP缓存中,而是根据对方给出的窗口值和当前网络拥塞的程度决定一个报文段应包含多少个字节。


1. TCP握手过程：


2. TCP挥手过程：

3. TCP缺点：
    * TCP可能会`间歇性`地`挂起数据传输`；
        * 如果一个序列号较低的数据段还没有接收到，即使其他序列号较高的段已经接收到，TCP的接收机滑动窗口也不会继续处理。这将导致`TCP流 瞬间挂起`，在更糟糕的情况下，即使所有的段中有一个没有收到，也会导致关闭连接。这个问题被称为TCP流的行头阻塞（HoL）。
    * TCP不支持`流级复用`
        * 虽然TCP确实允许在应用层之间建立多个逻辑连接，但它不允许在`一个TCP流中复用数据包`。使用HTTP/2时，浏览器只能与服务器打开一个TCP连接，并使用同一个连接来请求多个对象，如CSS、JavaScript等文件。在接收这些对象的同时，TCP会将所有对象序列化在同一个流中。因此，它不知道TCP段的对象级分区。
    * TCP会`产生冗余通信`
        * TCP连接握手会有冗余的消息交换序列，即使是与已知主机建立的连接也是如此。

### UDP (用户数据报协议 User Datagram Protocol)
* 特点：
    1. UDP是无连接，在发送数据之前不需要建立连接;
    2. UDP使用尽最大努力交付，不保证可靠交付，主机之间不需要维护负责的连接状态；
    3. UDP面向报文；
        * 发送方的UDP对 应用程序交下拉的报文，在添加首部后就向下交付IP层。
        * UDP对应用层交下来的报文，即不合并也不拆分，而是保留报文的边界。
        * 应用层交给UDP多长的报文，UDP照样发送，一次发送一个报文（一次交付一个完整的报文）。
        * 应用程序必须选择合适大小的报文，报文太长，UDP交给IP层后，IP层在传送时，可能要进行分片，这会降低IP层的效率；报文太短，IP数据报的首部相对长度太长，也降低IP层效率；
    4. 无拥塞控制
        * 网络出现的拥塞不会影响源主机的发送效率降低；
    5. UDP支持一对一，一对多，多对一，多对多的交互通信；
    6. UDP首部开销小(只有8字节，比TCP20字节首部要短)
    7. 在不影响实时性的前提下，增加一些提高可靠传输性的措施(前向纠错、重传已丢失的报文)；

### TCP与 UDP区别
* TCP面向连接(三次握手)的服务,UDP在发送数据之前不需要建立连接；
* TCP提供可靠服务.通过TCP连接传送的数据，`无差错，不丢失，不重复`，且`按序到达`;UDP尽最大努力交付，即不保证可靠交付.
* TCP有拥塞控制。UDP没有拥塞控制，因此`网络出现拥塞不会使源主机的发送速率降低`（对实时应用很有用，如IP电话，实时视频会议等）
* 每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信;
* TCP首部开销20字节;UDP的首部开销小，只有8个字节;
* TCP的`逻辑通信信道`是全双工的可靠信道，UDP则是不可靠信道;

### TCP的流量控制 （点对点通信量的控制  --抑制发送端的发送数据的速率）
* 利用滑动窗口实现
    * (一般情况，总希望数据传输的更快点，但是如果发送方 把数据发送的过快，接收方来不及接收，这就造成数据的丢失)。
    * 流量控制(flow control)：让发送方的`发送速率`不要太快，要让接收方来得及接收；(控制发送速率)
    * 利用滑动窗口机制实现 在TCP连接上实现 对发送方的流量控制；
    * TCP窗口单位字节（不是报文段）；
    * 在连接建立时，B告诉A“接收窗口 rwnd=400 rwnd“receiver window”,发送方的发送窗口不能超过接收方给的接收窗口的数量；
    * 考虑一种情况（零窗口 -- 死锁局面）。 -- 解决办法持续计时器
        * TCP为每一连接设有一个`持续计时器`(persistence timer);
        * 只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。
        * 若持续计时器设置的时间到期，就发送一个零窗口探测报文段(仅1字节的数据)，对方在确认这个探测报文段时给出一个现在的窗口值。
        * 如果还是零，那么重新设置持续计时器；
        * 如果不为零，打破死锁局面；

### TCP拥塞控制
* 目的：使网络中的路由器和链路不致过载；
* 前提：网络能够承载现有的网络负荷；
* 拥塞控制是一个全局性过程；
* 拥塞控制的方法(4种)
    * 慢启动(指数增长)
        * 当主机开始发送数据时，如果立即把大量数据字节注入到网络，有可能引起网络拥塞。（刚开始不清楚网络的负载情况）--先探测（由小到大逐渐增大发送窗口(拥塞窗口)）。cwnd
    * 拥塞避免（线性规律缓慢增加）
        * 让拥塞窗口缓慢增大。每经过一个RTT就把发送方的拥塞窗口(cwnd)加1,而不是加倍。
    * 快重传
    * 快恢复

### 参考文献
[Http 1.x弊端与Http 2.0比较](https://www.cnblogs.com/barrywxx/p/8570006.html)
